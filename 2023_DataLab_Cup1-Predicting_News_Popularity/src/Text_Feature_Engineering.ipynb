{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>DataLab Cup 1: Text Feature Engineering</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - To import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. To load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  49.6s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  50.9s\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('../dataset/train.csv')\n",
    "test_data  = pd.read_csv('../dataset/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11847, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Page content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt; &lt;span c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>&lt;html&gt;&lt;head&gt;&lt;div class=\"article-info\"&gt;&lt;span cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Popularity                                       Page content\n",
       "0   0          -1  <html><head><div class=\"article-info\"> <span c...\n",
       "1   1           1  <html><head><div class=\"article-info\"><span cl...\n",
       "2   2           1  <html><head><div class=\"article-info\"><span cl...\n",
       "3   3          -1  <html><head><div class=\"article-info\"><span cl...\n",
       "4   4          -1  <html><head><div class=\"article-info\"><span cl..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. To extract the features from the dataset\n",
    "\n",
    "將一些我們想要用到的feature從dataset中提取出來。以下為提取的特徵:\n",
    "\n",
    "- title\n",
    "- time(year/month/day/hour/minute/second)\n",
    "- number of images (num_img)\n",
    "- number of videos (num_video)\n",
    "- author name\n",
    "- topic\n",
    "- channel\n",
    "- length of content "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "* beautiful soup\n",
    "    - conda install -c conda-forge beautifulsoup4\n",
    "    \n",
    "<br>\n",
    "\n",
    "* vadersentiment\n",
    "    - conda install -c conda-forge vadersentiment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# to get the attribute of the 'title', 'year/month/date/day/hour/minute/second/is_weekend', 'num_img', 'num_video', 'author name', 'topic', 'channel', 'content length', 'title_sentiment'\n",
    "\n",
    "def preprocessor(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "\n",
    "    # 1. to find the 'title' (body > h1)\n",
    "    title = soup.find('h1').string.strip().lower()\n",
    "\n",
    "    # 2. to find time(body > div > span > time)\n",
    "\n",
    "    \n",
    "    date_string = soup.find('time')\n",
    "    try:\n",
    "        date_string = date_string['datetime']\n",
    "    except:\n",
    "        date_string = 'wed, 10 oct 2014 15:00:43 +0000'\n",
    "        \n",
    "    date_string = date_string.strip().lower()\n",
    "    datetimes = datetime.strptime(date_string, '%a, %d %b %Y %H:%M:%S %z')\n",
    "    \n",
    "    \n",
    "    year = datetimes.year\n",
    "    month = datetimes.month\n",
    "    date = datetimes.day\n",
    "    day = pd.Timestamp(str(year)+'-'+str(month)+'-'+str(date)).dayofweek+1\n",
    "    is_weekend = 1 if (day==6 or day==7) else 0\n",
    "    hour = datetimes.hour\n",
    "    minute = datetimes.minute\n",
    "    second = datetimes.second\n",
    "    \n",
    "\n",
    "    # 3. to find the number of images\n",
    "    num_img  = len(soup.find_all('img'))\n",
    "    \n",
    "\n",
    "    # 4. to find the number of videos\n",
    "    num_video = len(soup.find_all('iframe'))\n",
    "    \n",
    "\n",
    "    # 5. to find the author name\n",
    "    article_info = soup.find('div', class_='article-info')\n",
    "    author = article_info.find('span', class_='author_name') or article_info.find('span', class_='byline basic')\n",
    "\n",
    "    if (author != None):\n",
    "        if (author.find('a') != None):\n",
    "            author = author.find('a')\n",
    "            author_name = author.get_text().lower()\n",
    "        else :\n",
    "            author_name = author.get_text().lower()\n",
    "    else :\n",
    "        author_name = 'not found'\n",
    "    \n",
    "    \n",
    "\n",
    "    # 6. to find the article topic\n",
    "    footer = soup.find('footer', class_='article-topics')\n",
    "    topic = footer.get_text().split(': ')[1]\n",
    "    \n",
    "    # 7. to find the channel\n",
    "    channel = soup.find('article')['data-channel'].strip().lower()\n",
    "    \n",
    "    '''\n",
    "    print('title = ', title, type(title))\n",
    "    print('time = ', year, \"/\", month, \"/\",day, \" \",hour, \":\",minute, \":\",second, type(year))\n",
    "    print('number of images = ', num_img, type(num_img))\n",
    "    print('number of videos = ', num_video, type(num_video))\n",
    "    print('author_name = ', author_name, type(author_name))\n",
    "    print('topic = ', topic, type(topic))\n",
    "    print('channel = ', channel, type(channel))\n",
    "    '''\n",
    "    \n",
    "    # 8. to find the content length\n",
    "    content = soup.body.find('section', class_='article-content').get_text()\n",
    "    len_content = len(content)\n",
    "\n",
    "    # print('topic = ', topic, type(topic))\n",
    "    \n",
    "    # 9. to find the sentiment of title\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    title_sentiment = analyzer.polarity_scores(topic)\n",
    "    sentiment_neg = title_sentiment['neg']\n",
    "    sentiment_neu = title_sentiment['neu']\n",
    "    sentiment_pos = title_sentiment['pos']\n",
    "    sentiment_compound = title_sentiment['compound']\n",
    "\n",
    "    return title, author_name, channel, topic, year, month, date, day, is_weekend, hour, minute, second, num_img, num_video, len_content, sentiment_neg, sentiment_neu, sentiment_pos, sentiment_compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.4min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.4min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.5min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.4min\n",
      "[2, 2, 2] Finish!!\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.4min\n",
      "[2, 2, 1] Finish!!\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.5min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.4min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.4min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.1min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.0min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.0min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.5min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.5min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  27.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5843 (process_weight):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_53697/2761700238.py\", line 30, in process_weight\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 538, in release\n",
      "    raise ValueError(\"Semaphore released too many times\")\n",
      "ValueError: Semaphore released too many times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ....................... (3 of 3) Processing RF, total=  28.2s[Voting] .................. (1 of 3) Processing xgboost, total=  31.7s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  20.5s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  19.1s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  23.0s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  20.5s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  21.1s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  25.6s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  31.0s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  34.4s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  38.6s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  34.3s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  25.0s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  34.6s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  36.1s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.0min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.1min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.1min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.1min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.1min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.1min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.7min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  24.3s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  25.6s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  26.0s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  25.8s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  26.0s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  25.9s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  27.1s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.0min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  38.3s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  31.5s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  55.1s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  57.5s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  58.4s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  58.3s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.0min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.3min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  59.4s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.0min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.0min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.0min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.0min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  50.8s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  59.7s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  19.6s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  19.3s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  19.3s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  19.8s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  18.9s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.0min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  21.5s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  41.9s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  55.2s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  54.0s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.3min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.4min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.3min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.4min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.2min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  59.6s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.0min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.0min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.0min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total= 1.1min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.6min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total= 1.1min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  28.9s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  19.2s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  21.2s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  20.0s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  19.5s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  20.9s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  20.1s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.0min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  57.0s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  26.3s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.1min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.3min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  53.3s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  56.8s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.3min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.3min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  51.5s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  51.7s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  47.2s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  48.6s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  32.0s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  28.8s\n",
      "train score: 0.882522 (+/-0.003846)\n",
      "valid score: 0.598200 (+/-0.010468)\n",
      "train score: 0.919041 (+/-0.003487)\n",
      "valid score: 0.596691 (+/-0.010975)\n",
      "train score: 0.895458 (+/-0.003529)\n",
      "valid score: 0.595087 (+/-0.011330)\n",
      "train score: 0.939602 (+/-0.003171)\n",
      "valid score: 0.595134 (+/-0.011289)\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.3min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  33.2s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  42.4s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  41.2s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  41.0s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  48.6s\n",
      "train score: 0.871124 (+/-0.003593)\n",
      "valid score: 0.596793 (+/-0.010966)\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 3.8min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  35.9s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  41.0s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.8min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.9min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.3min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.5min\n",
      "train score: 0.960651 (+/-0.002558)\n",
      "valid score: 0.595672 (+/-0.010863)\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  49.2s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  54.2s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  54.6s\n",
      "[1, 2, 1] Finish!!\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 3.1min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  37.0s\n",
      "[2, 1, 2] Finish!!\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  43.2s\n",
      "train score: 0.934999 (+/-0.003179)\n",
      "valid score: 0.597368 (+/-0.010485)\n",
      "train score: nan (+/-nan)\n",
      "valid score: nan (+/-nan)\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  24.0s\n",
      "[2, 1, 1] Finish!!\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 3.4min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  21.9s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  22.9s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  24.1s\n",
      "[2, 2, 2] Finish!!\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.6min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  19.9s\n",
      "[2, 2, 1] Finish!!\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.1min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  16.5s\n",
      "[1, 1, 2] Finish!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception in threading.excepthook:\n",
      "Exception ignored in thread started by: <bound method Thread._bootstrap of <Thread(Thread-5842 (process_weight), stopped 140376190977792)>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 995, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 1040, in _bootstrap_inner\n",
      "    self._invoke_excepthook(self)\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 1352, in invoke_excepthook\n",
      "    local_print(\"Exception in threading.excepthook:\",\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/ipykernel/iostream.py\", line 575, in flush\n",
      "    self.pub_thread.schedule(self._flush)\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Exception in thread Thread-5845 (process_weight):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_53697/2761700238.py\", line 30, in process_weight\n",
      "  File \"/users/student/mr111/mfhsieh22/miniconda3/envs/DL/lib/python3.11/threading.py\", line 538, in release\n",
      "    raise ValueError(\"Semaphore released too many times\")\n",
      "ValueError: Semaphore released too many times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  53.0s[Voting] ..................... (2 of 3) Processing lgbm, total=  57.0s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=   9.4s\n",
      "[1, 2, 2] Finish!!\n"
     ]
    }
   ],
   "source": [
    "feature_train_list = []\n",
    "feature_test_list = []\n",
    "\n",
    "for content in (train_data['Page content']):\n",
    "    feature_train_list.append(preprocessor(content))\n",
    "for content in (test_data['Page content']):\n",
    "    feature_train_list.append(preprocessor(content))\n",
    "\n",
    "df_all = pd.DataFrame(\n",
    "        feature_train_list, \n",
    "        columns=['title', 'author_name', 'channel', 'topic', 'year', 'month', 'date', 'day', 'is_weekend', 'hour', 'minute', 'second', 'num_img', 'num_video', 'len_content', 'sentiment_neg', 'sentiment_neu', 'sentiment_pos', 'sentiment_compound'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1 . Preprocessing - tokenization\n",
    "\n",
    "To split the text corpora into individual elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenizer(text):\n",
    "    return re.split('\\s+', text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2 . Preprocessing - Word Stemming\n",
    "\n",
    "There are two ways of word stemming\n",
    "\n",
    "1. PorterStemmer(Stemming): break the word in rule-besed way, which will lead to the probelm of overstemming\n",
    "\n",
    "2. WordNetLemmatizer(Lemmatization): Stem the words will better performance, while time-consuming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['university,', 'universal,', 'university']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /users/student/mr111//mfhsieh22/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /users/student/mr111//mfhsieh22/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.data.path.append('/home/mfhsieh/NTHU-Deep-Learning-Competition/2023_DataLab_Cup1-Predicting_News_Popularity')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def word_stemming(text):\n",
    "    if type(text) == np.ndarray:\n",
    "        text = text[0]\n",
    "    lm = WordNetLemmatizer()\n",
    "    words = re.split('\\s', text.strip())\n",
    "    lemmatized_words = [lm.lemmatize(word) for word in words]\n",
    "    return lemmatized_words\n",
    "\n",
    "print(word_stemming('university, universal, universities'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['university,', 'universal,', 'univers']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def tokenizer_stem(text):\n",
    "    porter = PorterStemmer()\n",
    "    return [porter.stem(word) for word in re.split('\\s+', text.strip())]\n",
    "\n",
    "print(tokenizer_stem('university, universal, universities'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3 Preprocessing - Stop-Word Removal\n",
    "\n",
    "儘管刪除停用詞在某些情況下（例如 BoW 和特徵哈希）可以有益於簡化表示，並可能提高文字分析的準確性，但並不總是必要，特別是在使用 TF-IDF 時。是否刪除停用詞應基於文本分析任務的具體要求以及資料集的特性來進行決策"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['runner', 'like', 'run', 'thu', 'run']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /users/student/mr111//mfhsieh22/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def stop_word_removal(text):\n",
    "    porter = PorterStemmer()\n",
    "    return [porter.stem(w) for w in re.split('\\s+', text.strip()) \\\n",
    "            if w not in stop and re.match('[a-zA-Z]+', w)]\n",
    "\n",
    "print(stop_word_removal('runners like running and thus they run'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-5 Preprocessing - Word Stemming + Stop-Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_word_remove_stopword(text):\n",
    "    if type(text) == np.ndarray:\n",
    "        text = text[0]\n",
    "    lm = WordNetLemmatizer()\n",
    "    words = re.split('\\s', text.strip())\n",
    "    lemmatized_words = [lm.lemmatize(word) for word in words]\n",
    "    \n",
    "    filtered_list = [word for word in lemmatized_words if word not in stop]\n",
    "    \n",
    "    return filtered_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-5 Create TF-IDF feature representation ([ref](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ngram_range_ = (1,1)\n",
    "\n",
    "text_transformer = ColumnTransformer(\n",
    "    [\n",
    "        #('title preprocess', TfidfVectorizer(tokenizer=word_stemming, ngram_range=(1,1), lowercase=False), [0]),\n",
    "        ('author name process', TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=ngram_range_, lowercase=False), [0]),\n",
    "        #('channel process', TfidfVectorizer(tokenizer=word_stemming, ngram_range=(1,1), lowercase=False), [1]),\n",
    "        ('topic name process', TfidfVectorizer(tokenizer=word_stemming, token_pattern=None, ngram_range=ngram_range_, lowercase=False), [1]),\n",
    "    ],\n",
    "    remainder='passthrough', # do not touch the remaining data\n",
    "    n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vocabularies with smallest idf scores]\n",
      "to: 2.52\n",
      "the: 2.58\n",
      "in: 2.96\n",
      "a: 3.03\n",
      "of: 3.07\n",
      "for: 3.10\n",
      "and: 3.44\n",
      "is: 3.51\n",
      "on: 3.54\n",
      "your: 3.60\n",
      "\n",
      "[vocabularies with highest tf-idf scores]\n",
      "the: 1142.4830180213792\n",
      "to: 1109.6698985304176\n",
      "a: 795.7866740412087\n",
      "in: 787.5419357082401\n",
      "of: 746.7665375362841\n",
      "for: 734.8807138633431\n",
      "and: 555.5640584744767\n",
      "your: 551.5848064261177\n",
      "is: 544.621163447621\n",
      "you: 533.4917456688497\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=word_stemming, ngram_range=(1,1), lowercase=False)\n",
    "tfidf.fit(df_all['title'])\n",
    "top = 10\n",
    "# get idf score of vocabularies\n",
    "idf = tfidf.idf_\n",
    "print('[vocabularies with smallest idf scores]')\n",
    "sorted_idx = idf.argsort()\n",
    "\n",
    "for i in range(top):\n",
    "    print('%s: %.2f' %(tfidf.get_feature_names_out()[sorted_idx[i]], idf[sorted_idx[i]]))\n",
    "\n",
    "doc_tfidf = tfidf.transform(df_all['title']).toarray()\n",
    "tfidf_sum = np.sum(doc_tfidf, axis=0)\n",
    "print(\"\\n[vocabularies with highest tf-idf scores]\")\n",
    "for tok, v in zip(tfidf.inverse_transform(np.ones((1, tfidf_sum.shape[0])))[0][tfidf_sum.argsort()[::-1]][:top], \\\n",
    "                        np.sort(tfidf_sum)[::-1][:top]):\n",
    "    print('{}: {}'.format(tok, v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model training\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "- LightGBM\n",
    "\n",
    "- CatBoost\n",
    "\n",
    "- AdaBoost\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "- VotingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - To split the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>topic</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>hour</th>\n",
       "      <th>num_video</th>\n",
       "      <th>len_content</th>\n",
       "      <th>sentiment_neg</th>\n",
       "      <th>sentiment_neu</th>\n",
       "      <th>sentiment_pos</th>\n",
       "      <th>sentiment_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clara moskowitz</td>\n",
       "      <td>Asteroid, Asteroids, challenge, Earth, Space, ...</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3591</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>christina warren</td>\n",
       "      <td>Apps and Software, Google, open source, opn pl...</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1843</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sam laird</td>\n",
       "      <td>Entertainment, NFL, NFL Draft, Sports, Televis...</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>6646</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sam laird</td>\n",
       "      <td>Sports, Video, Videos, Watercooler</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1821</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>connor finnegan</td>\n",
       "      <td>Entertainment, instagram, instagram video, NFL...</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8919</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author_name                                              topic  year  \\\n",
       "0   clara moskowitz  Asteroid, Asteroids, challenge, Earth, Space, ...  2013   \n",
       "1  christina warren  Apps and Software, Google, open source, opn pl...  2013   \n",
       "2         sam laird  Entertainment, NFL, NFL Draft, Sports, Televis...  2014   \n",
       "3         sam laird                Sports, Video, Videos, Watercooler   2013   \n",
       "4   connor finnegan  Entertainment, instagram, instagram video, NFL...  2014   \n",
       "\n",
       "   month  date  day  is_weekend  hour  num_video  len_content  sentiment_neg  \\\n",
       "0      6    19    3           0    15          0         3591          0.000   \n",
       "1      3    28    4           0    17          0         1843          0.119   \n",
       "2      5     7    3           0    19         25         6646          0.000   \n",
       "3     10    11    5           0     2         21         1821          0.000   \n",
       "4      4    17    4           0     3          1         8919          0.000   \n",
       "\n",
       "   sentiment_neu  sentiment_pos  sentiment_compound  \n",
       "0          0.822          0.178              0.0772  \n",
       "1          0.881          0.000             -0.2263  \n",
       "2          0.641          0.359              0.4215  \n",
       "3          1.000          0.000              0.0000  \n",
       "4          0.641          0.359              0.4215  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_dict = [  #'title', \n",
    "                    'author_name', \n",
    "                    #'channel', \n",
    "                    'topic', \n",
    "                    'year', \n",
    "                    'month',\n",
    "                    'date', \n",
    "                    'day', \n",
    "                    'is_weekend',\n",
    "                    'hour', \n",
    "                    # 'minute', \n",
    "                    # 'second', \n",
    "                    # 'num_img', \n",
    "                    'num_video', \n",
    "                    'len_content',\n",
    "                    'sentiment_neg', \n",
    "                    'sentiment_neu', \n",
    "                    'sentiment_pos', \n",
    "                    'sentiment_compound'\n",
    "                    ]\n",
    "\n",
    "df = df_all.loc[:, remaining_dict]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27643, 14)\n",
      "<class 'numpy.ndarray'>\n",
      "[['clara moskowitz'\n",
      "  'Asteroid, Asteroids, challenge, Earth, Space, U.S., World ' 2013 ...\n",
      "  0.822 0.178 0.0772]\n",
      " ['christina warren'\n",
      "  'Apps and Software, Google, open source, opn pledge, patent lawsuit theater, software patents, Tech, U.S. '\n",
      "  2013 ... 0.881 0.0 -0.2263]\n",
      " ['sam laird' 'Entertainment, NFL, NFL Draft, Sports, Television ' 2014\n",
      "  ... 0.641 0.359 0.4215]\n",
      " ...\n",
      " ['christine erickson' 'Food, hot dogs, humor, Photography, Watercooler '\n",
      "  2014 ... 0.704 0.296 0.2732]\n",
      " ['seth fiegerman' 'Business, marissa mayer, Media, stocks, Yahoo ' 2013\n",
      "  ... 1.0 0.0 0.0]\n",
      " ['megan ranney' 'austin, Business, CurioCity, Small Business, Startups '\n",
      "  2014 ... 1.0 0.0 0.0]]\n",
      "(27643,)\n",
      "<class 'numpy.ndarray'>\n",
      "[0 1 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = df.values[:train_data.shape[0]]\n",
    "y_train = train_data['Popularity'].values\n",
    "y_train[y_train==-1] = 0\n",
    "X_test = df.values[train_data.shape[0]:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(type(X_train))\n",
    "print(X_train)\n",
    "print(y_train.shape)\n",
    "print(type(y_train))\n",
    "print(y_train)\n",
    "\n",
    "X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - To construct the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def training(clf):\n",
    "    score = cross_validate(clf, X_train, y_train, scoring='roc_auc', return_train_score=True, return_estimator=True)\n",
    "    print('train score: {:.6f} (+/-{:.6f})'.format(\n",
    "        np.mean(score['train_score']), np.std(score['train_score'])))\n",
    "    print('valid score: {:.6f} (+/-{:.6f})'.format(\n",
    "        np.mean(score['test_score']), np.std(score['test_score'])))\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf, np.mean(score['train_score']), np.mean(score['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - To contruct the grid search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_search_cv(ct, clf, param_grid, verbose_=False):\n",
    "    X_train_ct = ct.fit_transform(X_train)\n",
    "    \n",
    "    # to report the grid search information\n",
    "    if(verbose_):\n",
    "        gs = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc', n_jobs=-1, cv=5, return_train_score=True, verbose = 2)\n",
    "    else:\n",
    "        gs = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc', n_jobs=-1, cv=5, return_train_score=True)\n",
    "    gs.fit(X_train_ct, y_train)\n",
    "    \n",
    "    results, idx = gs.cv_results_, gs.best_index_\n",
    "    print('train score: {:.6f} (+/-{:.6f})'.format(results['mean_train_score'][idx], results['std_train_score'][idx]))\n",
    "    print('valid score: {:.6f} (+/-{:.6f})'.format(results['mean_test_score'][idx], results['std_test_score'][idx]))\n",
    "    print('best params:', gs.best_params_)\n",
    "    return gs.best_params_, gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- To set whether to run the grid search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_en = True\n",
    "# grid_search_en = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - to store the best parameter to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_storage(dict_path, file_name, best_xgb_param):\n",
    "    if not os.path.exists(dict_path):\n",
    "        os.makedirs(dict_path)\n",
    "        \n",
    "    file_path = os.path.join(dict_path, file_name + \".txt\")\n",
    "    \n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(f'The features: {remaining_dict}\\n')\n",
    "        file.write(f'The best parameter: {best_xgb_param}\\n')\n",
    "        file.write(f'ngram_range_: {ngram_range_}')\n",
    "        file.write('--------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-1-1. Grid sizing for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_xgb = {\n",
    "    'gamma' : [0.8, 0.9, 1, 1.1, 1.2],\n",
    "    'lambda' : [2.3, 2.4, 2.5],\n",
    "    'n_estimators': [97, 98, 99, 100, 101, 102, 103],\n",
    "    'max_depth': [7, 8, 9],\n",
    "    'learning_rate' : [0.137, 0.138, 0.139, 0.14, 0.141, 0.142, 0.143]  \n",
    "}\n",
    "\n",
    "# param_grid_xgb = {\n",
    "#     'lambda' : [2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3]  \n",
    "# }\n",
    "\n",
    "if (grid_search_en):\n",
    "    best_xgb_param, best_xgb = grid_search_cv(text_transformer, XGBClassifier(n_jobs=-1), param_grid_xgb, True)\n",
    "    parameter_storage('../output/best_parameters', 'best_xgb_param', best_xgb_param)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-1-2. Training for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.815946 (+/-0.003000)\n",
      "valid score: 0.588796 (+/-0.011443)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'gamma' : 1,\n",
    "    'lambda' : 2.5,\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate' : 0.14,\n",
    "    'n_jobs' : -1\n",
    "}\n",
    "\n",
    "if (grid_search_en):\n",
    "    xgboost = Pipeline([('vect', text_transformer), ('clf', best_xgb)])\n",
    "else :\n",
    "    xgboost = Pipeline([('vect', text_transformer), ('clf', XGBClassifier(**param_grid_lgbm))])\n",
    "    \n",
    "_ = training(xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-2-1. Grid sizing for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lgbm = {\n",
    "    'learning_rate' : [0.013, 0.0135 , 0.0136, 0.0137, 0.0138, 0.0139, 0.014, 0.0141, 0.0142, 0.0143, 0.0144 ,0.0145, 0.015], \n",
    "    'n_estimators' : [230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250],\n",
    "    'objective' : ['regression', 'regression_l1', 'poisson']\n",
    "}\n",
    "\n",
    "if (grid_search_en):\n",
    "    best_lgbm_param, best_lgbm = grid_search_cv(text_transformer, LGBMClassifier(n_jobs=-1, verbose=-1), param_grid_lgbm, True)\n",
    "    parameter_storage('../output/best_parameters', 'best_lgbm_param', best_lgbm_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-2-2. Training for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.669064 (+/-0.002302)\n",
      "valid score: 0.596976 (+/-0.007465)\n"
     ]
    }
   ],
   "source": [
    "params_LGBM = {\n",
    "    'random_state': 0, \n",
    "    'learning_rate' : 0.014,\n",
    "    'n_estimators' : 240,\n",
    "    'n_jobs' : -1,\n",
    "    'objective' : 'poisson'\n",
    "}\n",
    "\n",
    "if (grid_search_en):\n",
    "    lgbm = Pipeline([('vect', text_transformer), ('clf', best_lgbm)])\n",
    "else :\n",
    "    lgbm = Pipeline([('vect', text_transformer), ('clf', LGBMClassifier(**params_LGBM))])\n",
    "\n",
    "_ = training(lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3. CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-3-1. Grid sizing for Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_catboost = {\n",
    "    'learning_rate' : [0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03], \n",
    "    'n_estimators' : [450, 500, 550],\n",
    "    'depth' : [9, 10, 11]\n",
    "}\n",
    "\n",
    "if (grid_search_en):\n",
    "    best_cat_params, best_cat_estimator = grid_search_cv(text_transformer, CatBoostClassifier(eval_metric='AUC',random_state=0, verbose=False), param_grid_catboost, True)\n",
    "    parameter_storage('../output/best_parameters', 'best_cat_params', best_cat_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-3-2. Training for CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.694347 (+/-0.002958)\n",
      "valid score: 0.597723 (+/-0.009453)\n"
     ]
    }
   ],
   "source": [
    "paramsCatBoost = {\n",
    "    'eval_metric' : 'AUC',\n",
    "    'n_estimators' : 500,\n",
    "    'depth' : 10,\n",
    "    'learning_rate' : 0.01,\n",
    "    'random_state' : 0,\n",
    "    'verbose' : False\n",
    "}\n",
    "\n",
    "if (grid_search_en):\n",
    "    catboost = Pipeline([('ct', text_transformer),('clf', best_cat_estimator)])\n",
    "else :\n",
    "    catboost = Pipeline([('ct', text_transformer),('clf', CatBoostClassifier(**paramsCatBoost))])\n",
    "\n",
    "_ = training(catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4. AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-4-1. Grid sizing for AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params_grid_AdaBoost = {\n",
    "    'clf__estimator__max_depth' : [1,2,3,4,5,6,7,8,9,10],\n",
    "    'clf__n_estimators': [num for num in range(50, 1000, 50)],\n",
    "    'clf__learning_rate': [0.005, 0.01, 0.05, 0.1, 0.5] \n",
    "}\n",
    "\n",
    "if (grid_search_en):\n",
    "    best_ada_params, best_ada_estimator = grid_search_cv(text_transformer, \n",
    "                                                         AdaBoostClassifier(estimator=DecisionTreeClassifier(), n_jobs=-1), \n",
    "                                                         params_grid_AdaBoost, True)\n",
    "    parameter_storage('../output/best_parameters', 'best_ada_params', best_ada_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-4-2. Training for AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.680774 (+/-0.005286)\n",
      "valid score: 0.586246 (+/-0.007764)\n"
     ]
    }
   ],
   "source": [
    "param_Adaboost = {\n",
    "    'estimator' : DecisionTreeClassifier(max_depth = 4), \n",
    "    'learning_rate' : 0.005, \n",
    "    'n_estimators' : 900\n",
    "}\n",
    "\n",
    "if (grid_search_en):\n",
    "    adaBoost = Pipeline([('vect', text_transformer), ('clf', best_ada_estimator)])\n",
    "else :\n",
    "    adaBoost = Pipeline([('vect', text_transformer), ('clf', AdaBoostClassifier(**param_Adaboost))])\n",
    "    \n",
    "_ = training(adaBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-5. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-5-1. Grid sizing for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params_grid_RF = {\n",
    "    'n_estimator' : {800, 900, 1000, 1100},\n",
    "    'max_depth' : {70, 80, 90}\n",
    "}\n",
    "\n",
    "if (grid_search_en):\n",
    "    best_RF_params, best_RF_estimator = grid_search_cv(text_transformer, RandomForestClassifier(n_jobs=-1), params_grid_RF, True)\n",
    "    parameter_storage('../output/best_parameters', 'best_RF_params', best_RF_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-5-2. Training for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.997939 (+/-0.000347)\n",
      "valid score: 0.585703 (+/-0.010655)\n"
     ]
    }
   ],
   "source": [
    "param_RF = {\n",
    "    'n_jobs' : -1,\n",
    "    'random_state' : 0,\n",
    "    'n_estimators' : 1000,\n",
    "    'max_depth' : 80\n",
    "}\n",
    "\n",
    "if (grid_search_en):\n",
    "    RF = Pipeline([('vect', text_transformer), ('clf', best_RF_estimator)])\n",
    "else :\n",
    "    RF = Pipeline([('vect', text_transformer), ('clf', RandomForestClassifier(**param_RF))])\n",
    "    \n",
    "_ = training(RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-6. VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-2-1. Grid sizing for Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classifier = 3\n",
    "weight_range = 2\n",
    "estimator_list = [('xgboost', xgboost), ('lgbm', lgbm), ('RF', RF)]\n",
    "# estimator_list = [('xgboost', xgboost), ('lgbm', lgbm), ('catboost', catboost), ('adaBoost', adaBoost), ('RF', RF)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(estimator_list) != num_classifier) :\n",
    "    print(\"Error: the numver of the classifier must equal to the estimator_list element number! Please check again!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to find the weight combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def weight_list_generator(weight_range_, num_classifier_):   \n",
    "    weight_range = weight_range_\n",
    "    weight_list = []\n",
    "\n",
    "    binary_values = (i for i in range(1, weight_range+1))\n",
    "    weight_list = [list(i) for i in list(itertools.product(binary_values, repeat=num_classifier_))]\n",
    "\n",
    "    print('weight list = ', weight_list)\n",
    "    print('length of weight list = ', len(weight_list))\n",
    "    return weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight list =  [[1, 1, 1], [1, 1, 2], [1, 2, 1], [1, 2, 2], [2, 1, 1], [2, 1, 2], [2, 2, 1], [2, 2, 2]]\n",
      "length of weight list =  8\n"
     ]
    }
   ],
   "source": [
    "weight_list = weight_list_generator(weight_range_ = weight_range, \n",
    "                      num_classifier_ = num_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* multi-thread grid search for voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current weight = [1, 1, 1]\n",
      "current weight = [1, 1, 2]\n",
      "current weight = [1, 2, 1]\n",
      "current weight = [1, 2, 2]\n",
      "current weight = [2, 1, 1]\n",
      "current weight = [2, 1, 2]\n",
      "current weight = [2, 2, 1]\n",
      "current weight = [2, 2, 2]\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  12.6s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  14.3s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  14.4s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  17.7s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  17.9s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  18.1s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  21.8s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  23.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  31.1s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  27.5s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  31.5s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  31.8s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  36.9s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  52.2s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  47.4s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.1min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.1min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.1min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  59.9s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  49.3s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.9min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  30.4s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  31.1s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  29.4s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  29.7s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  33.7s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  31.1s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  30.2s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.4min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  31.4s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  45.4s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  51.1s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  57.5s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  49.9s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  52.6s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  31.5s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.3min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  55.9s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  56.1s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  56.9s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  57.0s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  56.4s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  35.7s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total= 1.1min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  14.1s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  16.2s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  17.3s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  17.4s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  18.7s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.4min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  32.9s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  19.6s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  50.8s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  52.1s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.2min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.2min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.2min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.3min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  49.1s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  51.0s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.1min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  57.2s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  54.8s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  47.6s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  47.8s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  23.4s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.5min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  16.4s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  19.6s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  24.0s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  26.1s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  30.8s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.1min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.2min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  22.6s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  48.2s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  49.6s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.5min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  34.0s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.6min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.6min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  39.6s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  45.0s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.1min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  41.6s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  55.1s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  28.6s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  51.6s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  16.6s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.4min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  16.5s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  24.1s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  32.9s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.1min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  29.5s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=  55.1s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  43.8s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  45.7s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.6min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  40.4s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  26.3s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.8min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.0min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.9min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  38.2s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  40.7s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  43.7s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  44.7s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  38.9s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.3min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  35.7s\n",
      "train score: 0.882522 (+/-0.003846)\n",
      "valid score: 0.598200 (+/-0.010468)\n",
      "train score: 0.895458 (+/-0.003529)\n",
      "valid score: 0.595087 (+/-0.011330)\n",
      "train score: 0.939602 (+/-0.003171)\n",
      "valid score: 0.595134 (+/-0.011289)\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  28.2s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.8min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  30.4s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.0min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  31.2s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.2min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  29.2s\n",
      "train score: 0.871124 (+/-0.003593)\n",
      "valid score: 0.596793 (+/-0.010966)\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  49.9s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  53.2s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  54.0s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  45.3s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.7min\n",
      "train score: 0.919041 (+/-0.003487)\n",
      "valid score: 0.596691 (+/-0.010975)\n",
      "train score: 0.919041 (+/-0.003487)\n",
      "valid score: 0.596691 (+/-0.010975)\n",
      "train score: 0.960651 (+/-0.002558)\n",
      "valid score: 0.595672 (+/-0.010863)\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  29.3s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.6min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.6min\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  29.9s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  30.6s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  29.8s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.9min\n",
      "train score: 0.934999 (+/-0.003179)\n",
      "valid score: 0.597368 (+/-0.010485)\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.0min\n",
      "[2, 1, 1] Finish!!\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.1min\n",
      "[2, 1, 2] Finish!!\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=  49.0s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total= 1.1min\n",
      "[1, 2, 1] Finish!!\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 2.0min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  28.8s\n",
      "[2, 2, 1] Finish!!\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.8min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.8min\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.8min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  27.9s\n",
      "[1, 1, 2] Finish!!\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=  30.3s\n",
      "[1, 1, 1] Finish!!\n",
      "end once\n",
      "best_valid_score = 0.598200\n",
      "best_weight =  [1, 2, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ....................... (3 of 3) Processing RF, total=  28.6s\n",
      "[2, 2, 2] Finish!!\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total= 1.2min\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=   6.0s\n",
      "[1, 2, 2] Finish!!\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "param_grid_voting_static = {\n",
    "    'estimators' : estimator_list,\n",
    "    'voting' : 'soft',\n",
    "    'flatten_transform' : True, \n",
    "    'verbose' : True\n",
    "}\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "\n",
    "def process_weight(weight):\n",
    "    # share in multiple threads\n",
    "    global best_valid_score, best_weight, best_voting\n",
    "\n",
    "    voting = VotingClassifier(**param_grid_voting_static, weights=weight)\n",
    "    print('current weight =', weight)\n",
    "    clf_voting, _, valid_voting = training(voting)\n",
    "\n",
    "    # to protect the safety of shared variables\n",
    "    with lock:\n",
    "        if valid_voting > best_valid_score:\n",
    "            best_valid_score = valid_voting\n",
    "            best_weight = weight\n",
    "            best_voting = clf_voting\n",
    "    \n",
    "    print(f'{weight} Finish!!')\n",
    "    threadmax.release()\n",
    "\n",
    "'''\n",
    "def process_weight(weight):\n",
    "    # share in multiple threads\n",
    "    global best_valid_score, best_weight, best_voting\n",
    "\n",
    "    voting = VotingClassifier(**param_grid_voting_static, weights=weight)\n",
    "    print('current weight =', weight)\n",
    "    valid_voting = 2\n",
    "\n",
    "    # to protect the safety of shared variables\n",
    "    with lock:\n",
    "        if valid_voting >= best_valid_score:\n",
    "            best_valid_score = valid_voting\n",
    "            best_weight = weight\n",
    "    \n",
    "    print(f'{weight} Finish!!')\n",
    "    threadmax.release()\n",
    "''' \n",
    "        \n",
    "if (1):\n",
    "    best_valid_score = 0\n",
    "    best_weight = None\n",
    "    best_voting = None\n",
    "    mem = []\n",
    "    threadmax = threading.BoundedSemaphore(64)\n",
    "    \n",
    "    for weight in weight_list:\n",
    "        threadmax.acquire()\n",
    "        thread = threading.Thread(target=process_weight, args=(weight,))\n",
    "    \n",
    "        thread.start()\n",
    "        mem.append(thread)\n",
    "\n",
    "    for thread in mem:\n",
    "        thread.join()\n",
    "        mem.remove(thread)\n",
    "    \n",
    "    print('end once')\n",
    "\n",
    "    print('best_valid_score = %.6f' % best_valid_score)\n",
    "    print('best_weight = ', best_weight)\n",
    "    \n",
    "    parameter_storage('../output/best_parameters', 'best_weight', best_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# param_grid_voting = {\n",
    "#     'weight' : weight_list\n",
    "# }\n",
    "\n",
    "# param_grid_voting_static = {\n",
    "#     'estimators' : estimator_list,\n",
    "#     'voting' : 'soft',\n",
    "#     'flatten_transform' : True, \n",
    "#     'verbose' : True\n",
    "# }\n",
    "\n",
    "# print(param_grid_voting['weight'])\n",
    "\n",
    "# best_valid_score = 0\n",
    "# best_weight = []\n",
    "\n",
    "# # grid search for the weight of voting classifier\n",
    "# if (grid_search_en):\n",
    "#     for weight in param_grid_voting['weight']:\n",
    "#         voting = VotingClassifier(**param_grid_voting_static, weights=weight)\n",
    "#         clf_voting, train_voting, valid_voting = training(voting)\n",
    "#         if(valid_voting>best_valid_score):\n",
    "#             best_valid_score = valid_voting\n",
    "#             best_weight = weight\n",
    "#             best_voting = clf_voting\n",
    "\n",
    "# print('best_valid_score = ', best_valid_score)\n",
    "# print('best_weight = ', best_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] .................. (1 of 3) Processing xgboost, total=  29.3s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=   6.2s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=   6.8s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=   3.2s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=   5.8s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=   5.7s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=   3.3s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=   5.0s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=   5.3s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=   3.3s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=   5.8s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=   4.8s\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=   2.9s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=   6.0s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=   5.2s\n",
      "train score: 0.882522 (+/-0.003846)\n",
      "valid score: 0.598200 (+/-0.010468)\n",
      "[Voting] .................. (1 of 3) Processing xgboost, total=   3.0s\n",
      "[Voting] ..................... (2 of 3) Processing lgbm, total=   5.9s\n",
      "[Voting] ....................... (3 of 3) Processing RF, total=   5.8s\n"
     ]
    }
   ],
   "source": [
    "# no n_jobs\n",
    "prarms_voting = {\n",
    "    'estimators' : estimator_list, \n",
    "    'voting' : 'soft',\n",
    "    'weights' : [1, 2, 1],\n",
    "    'flatten_transform' : True,\n",
    "    'verbose' : True\n",
    "}\n",
    "\n",
    "if (grid_search_en):\n",
    "    voting = VotingClassifier(**param_grid_voting_static, weights=best_weight)\n",
    "else :\n",
    "    voting = VotingClassifier(**prarms_voting)\n",
    "\n",
    "_ = training(voting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testing data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = voting\n",
    "\n",
    "y_score = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "df_pred = pd.DataFrame({'Id': test_data['Id'], 'Popularity': y_score})\n",
    "df_pred.to_csv('../output/test_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
