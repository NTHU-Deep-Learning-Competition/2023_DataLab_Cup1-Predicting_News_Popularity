{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Popularity                                       Page content\n",
      "0   0          -1  <html><head><div class=\"article-info\"> <span c...\n",
      "1   1           1  <html><head><div class=\"article-info\"><span cl...\n",
      "2   2           1  <html><head><div class=\"article-info\"><span cl...\n",
      "3   3          -1  <html><head><div class=\"article-info\"><span cl...\n",
      "4   4          -1  <html><head><div class=\"article-info\"><span cl...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('./dataset/news/train.csv')\n",
    "df_test = pd.read_csv('./dataset/news/test.csv')\n",
    "print(df_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "features = []\n",
    "for i, html_content in enumerate(df_train[\"Page content\"][:100]):\n",
    "    # 使用 BeautifulSoup 解析 HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # 提取作者\n",
    "    article_info = soup.head.find('div', class_='article-info')\n",
    "    author_name = article_info.find('span', class_='author_name')\n",
    "    if author_name != None:\n",
    "        author = author_name.text\n",
    "    elif article_info.find('span') != None:\n",
    "        author = article_info.find('span').text\n",
    "    else:\n",
    "        author = article_info.find('a').text\n",
    "    \n",
    "    author = re.sub(r'^[Bb]y\\s+', \"\", author)\n",
    "    authors = re.split(r', | and | & ', author)\n",
    "    authors = [author.strip() for author in authors]\n",
    "    \n",
    "    # 提取時間\n",
    "    time = soup.head.find('time')['datetime']\n",
    "    # 使用正則表示式提取時間訊息\n",
    "    match = re.search(r'(\\w+), (\\d+) (\\w+) (\\d+) (\\d+):(\\d+):(\\d+)', time) # Wed, 19 Jun 2013 15:04:30 +0000\n",
    "    if match:\n",
    "        day_of_week, day, month, year, hour, minute, second = match.groups()\n",
    "    else:\n",
    "        print(\"No match found\")\n",
    "\n",
    "    day_of_week_map = {'Mon': 1, 'Tue': 2, 'Wed': 3, 'Thu': 4, 'Fri': 5, 'Sat': 6, 'Sun': 7}\n",
    "    month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "    \n",
    "    day_of_week = day_of_week_map[day_of_week]\n",
    "    month = month_map[month]\n",
    "    \n",
    "\n",
    "    # 提取標題\n",
    "    title = soup.body.find('h1', class_='title').text\n",
    "\n",
    "    # 提取频道\n",
    "    channel = soup.body.find('article')['data-channel']\n",
    "\n",
    "    # 提取主题\n",
    "    topics = [a.text for a in soup.body.find('footer', class_='article-topics').find_all('a')]\n",
    "\n",
    "    # 計算超連結数量\n",
    "    num_links = len(soup.body.find_all('a', href=True))\n",
    "\n",
    "    # 計算圖片數量\n",
    "    num_images = len(soup.body.find_all('img', class_='microcontent'))\n",
    "\n",
    "    # 提取内容長度\n",
    "    content_len = len(soup.body.find('section', class_='article-content').text.strip())\n",
    "\n",
    "    # 添加數據到DataFrame\n",
    "    # features.append({'Title': title, 'Author': authors, 'Day of Week': day_of_week, 'Day': int(day), 'Month': month,\n",
    "    #                 'Year': int(year), 'Hour': int(hour), 'Minute': int(minute), 'Second': int(second), 'Channel': channel,\n",
    "    #                 'Topics': topics, 'Hyperlinks': num_links, 'Images': num_images, 'Content_len': content_len})\n",
    "    \n",
    "    features.append({'Day of Week': day_of_week, 'Day': int(day), 'Month': month,\n",
    "                    'Year': int(year), 'Hour': int(hour), 'Minute': int(minute), 'Second': int(second), 'Channel': channel,\n",
    "                    'Topics': topics, 'Hyperlinks': num_links, 'Images': num_images, 'Content_len': content_len})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 12)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "df_X = pd.DataFrame(features)\n",
    "df_y = df_train[\"Popularity\"][:100]\n",
    "print(df_X.shape)\n",
    "print(df_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Second</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Hyperlinks</th>\n",
       "      <th>Images</th>\n",
       "      <th>Content_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>world</td>\n",
       "      <td>[Asteroid, Asteroids, challenge, Earth, Space,...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "      <td>tech</td>\n",
       "      <td>[Apps and Software, Google, open source, opn p...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>[Entertainment, NFL, NFL Draft, Sports, Televi...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>watercooler</td>\n",
       "      <td>[Sports, Video, Videos, Watercooler]</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>[Entertainment, instagram, instagram video, NF...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>8908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>30</td>\n",
       "      <td>world</td>\n",
       "      <td>[Australia, brisbane, Climate, floods, Queensl...</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>world</td>\n",
       "      <td>[archaeology, artifact, UK, World]</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>26</td>\n",
       "      <td>gaming</td>\n",
       "      <td>[Entertainment, gallery, Gaming, iOS games, Te...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>58</td>\n",
       "      <td>world</td>\n",
       "      <td>[Space, snow, U.S., World, Climate]</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>4260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>music</td>\n",
       "      <td>[drake, emojis, Entertainment, instagram, Musi...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Day of Week  Day  Month  Year  Hour  Minute  Second        Channel  \\\n",
       "0             3   19      6  2013    15       4      30          world   \n",
       "1             4   28      3  2013    17      40      55           tech   \n",
       "2             3    7      5  2014    19      15      20  entertainment   \n",
       "3             5   11     10  2013     2      26      50    watercooler   \n",
       "4             4   17      4  2014     3      31      43  entertainment   \n",
       "..          ...  ...    ...   ...   ...     ...     ...            ...   \n",
       "95            4   20     11  2014     3      54      30          world   \n",
       "96            5   18      4  2014    16      22       5          world   \n",
       "97            4   17      1  2013    22      50      26         gaming   \n",
       "98            5    3      1  2014    17      42      58          world   \n",
       "99            4   25      9  2014    18      41      50          music   \n",
       "\n",
       "                                               Topics  Hyperlinks  Images  \\\n",
       "0   [Asteroid, Asteroids, challenge, Earth, Space,...          21       1   \n",
       "1   [Apps and Software, Google, open source, opn p...          16       1   \n",
       "2   [Entertainment, NFL, NFL Draft, Sports, Televi...           9       1   \n",
       "3                [Sports, Video, Videos, Watercooler]          11       0   \n",
       "4   [Entertainment, instagram, instagram video, NF...          14       1   \n",
       "..                                                ...         ...     ...   \n",
       "95  [Australia, brisbane, Climate, floods, Queensl...          35       1   \n",
       "96                 [archaeology, artifact, UK, World]          14       1   \n",
       "97  [Entertainment, gallery, Gaming, iOS games, Te...           8       1   \n",
       "98                [Space, snow, U.S., World, Climate]          39       1   \n",
       "99  [drake, emojis, Entertainment, instagram, Musi...          17       1   \n",
       "\n",
       "    Content_len  \n",
       "0          3588  \n",
       "1          1841  \n",
       "2          6638  \n",
       "3          1815  \n",
       "4          8908  \n",
       "..          ...  \n",
       "95         2503  \n",
       "96         3179  \n",
       "97         5105  \n",
       "98         4260  \n",
       "99         1366  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/s111062588/deep_learning/competition01/competition01.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B140.114.75.93-tclab-dl2-root/home/s111062588/deep_learning/competition01/competition01.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df_X[\u001b[39m\"\u001b[39;49m\u001b[39mTopics\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49munique()\n",
      "File \u001b[0;32m~/miniconda3/envs/DL/lib/python3.9/site-packages/pandas/core/series.py:2194\u001b[0m, in \u001b[0;36mSeries.unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munique\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ArrayLike:  \u001b[39m# pylint: disable=useless-parent-delegation\u001b[39;00m\n\u001b[1;32m   2132\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2133\u001b[0m \u001b[39m    Return unique values of Series object.\u001b[39;00m\n\u001b[1;32m   2134\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2192\u001b[0m \u001b[39m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[1;32m   2193\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2194\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49munique()\n",
      "File \u001b[0;32m~/miniconda3/envs/DL/lib/python3.9/site-packages/pandas/core/base.py:1030\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     result \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39munique()\n\u001b[1;32m   1029\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1030\u001b[0m     result \u001b[39m=\u001b[39m algorithms\u001b[39m.\u001b[39;49munique1d(values)\n\u001b[1;32m   1031\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/DL/lib/python3.9/site-packages/pandas/core/algorithms.py:390\u001b[0m, in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munique\u001b[39m(values):\n\u001b[1;32m    297\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[39m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m unique_with_mask(values)\n",
      "File \u001b[0;32m~/miniconda3/envs/DL/lib/python3.9/site-packages/pandas/core/algorithms.py:429\u001b[0m, in \u001b[0;36munique_with_mask\u001b[0;34m(values, mask)\u001b[0m\n\u001b[1;32m    427\u001b[0m table \u001b[39m=\u001b[39m hashtable(\u001b[39mlen\u001b[39m(values))\n\u001b[1;32m    428\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 429\u001b[0m     uniques \u001b[39m=\u001b[39m table\u001b[39m.\u001b[39;49munique(values)\n\u001b[1;32m    430\u001b[0m     uniques \u001b[39m=\u001b[39m _reconstruct_data(uniques, original\u001b[39m.\u001b[39mdtype, original)\n\u001b[1;32m    431\u001b[0m     \u001b[39mreturn\u001b[39;00m uniques\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7247\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.unique\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7194\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "df_X[\"Topics\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input to be uniformly strings or numbers. Got ['list']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/DL/lib/python3.9/site-packages/sklearn/utils/_encode.py:171\u001b[0m, in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m     uniques_set \u001b[39m=\u001b[39m \u001b[39mset\u001b[39;49m(values)\n\u001b[1;32m    172\u001b[0m     uniques_set, missing_values \u001b[39m=\u001b[39m _extract_missing(uniques_set)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/s111062588/deep_learning/competition01/competition01.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.114.75.93-tclab_dl2_root/home/s111062588/deep_learning/competition01/competition01.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m preprocessing\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.114.75.93-tclab_dl2_root/home/s111062588/deep_learning/competition01/competition01.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m labelen \u001b[39m=\u001b[39m preprocessing\u001b[39m.\u001b[39mLabelEncoder()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B140.114.75.93-tclab_dl2_root/home/s111062588/deep_learning/competition01/competition01.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m df_X[\u001b[39m\"\u001b[39m\u001b[39mAuthor\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m labelen\u001b[39m.\u001b[39;49mfit_transform(df_X[\u001b[39m\"\u001b[39;49m\u001b[39mAuthor\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniconda3/envs/DL/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/DL/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115\u001b[0m, in \u001b[0;36mLabelEncoder.fit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit label encoder and return encoded labels.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[1;32m    104\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m    Encoded labels.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_, y \u001b[39m=\u001b[39m _unique(y, return_inverse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    116\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/miniconda3/envs/DL/lib/python3.9/site-packages/sklearn/utils/_encode.py:42\u001b[0m, in \u001b[0;36m_unique\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Helper function to find unique values with support for python objects.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[39mUses pure python method for object dtype, and numpy method for\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m    array. Only provided if `return_counts` is True.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m _unique_python(\n\u001b[1;32m     43\u001b[0m         values, return_inverse\u001b[39m=\u001b[39;49mreturn_inverse, return_counts\u001b[39m=\u001b[39;49mreturn_counts\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m \u001b[39m# numerical\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39mreturn\u001b[39;00m _unique_np(\n\u001b[1;32m     47\u001b[0m     values, return_inverse\u001b[39m=\u001b[39mreturn_inverse, return_counts\u001b[39m=\u001b[39mreturn_counts\n\u001b[1;32m     48\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/DL/lib/python3.9/site-packages/sklearn/utils/_encode.py:179\u001b[0m, in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     types \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(t\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(\u001b[39mtype\u001b[39m(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values))\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    180\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEncoders require their input to be uniformly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstrings or numbers. Got \u001b[39m\u001b[39m{\u001b[39;00mtypes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    183\u001b[0m ret \u001b[39m=\u001b[39m (uniques,)\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m return_inverse:\n",
      "\u001b[0;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['list']"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "labelen = preprocessing.LabelEncoder()\n",
    "df_X[\"Author\"] = labelen.fit_transform(df_X[\"Author\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance (Decision Tree):\n",
      "[0.07241718 0.11079482 0.08333025 0.012505   0.14576546 0.10246802\n",
      " 0.09564964 0.15002395 0.02221226 0.20483341]\n",
      "Selected Features (SelectKBest):\n",
      "Index(['Day of Week', 'Day', 'Hour', 'Hyperlinks', 'Images'], dtype='object')\n",
      "Feature Importance (Random Forest):\n",
      "[0.09038014 0.11990177 0.08867318 0.02553292 0.11402645 0.12356174\n",
      " 0.13310079 0.1265391  0.01923169 0.15905223]\n",
      "Accuracy (Decision Tree): 0.475\n",
      "Accuracy (Random Forest): 0.555\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 劃分數據集為訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 方法1: 使用決策樹進行特徵選擇\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "feature_importance = clf.feature_importances_\n",
    "print(\"Feature Importance (Decision Tree):\")\n",
    "print(feature_importance)\n",
    "\n",
    "# 方法2: 使用SelectKBest和f_classif進行特徵選擇\n",
    "selector = SelectKBest(score_func=f_classif, k=5)  # 選擇前5個特徵\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "selected_features = df_X.columns[selected_feature_indices]\n",
    "print(\"Selected Features (SelectKBest):\")\n",
    "print(selected_features)\n",
    "\n",
    "# 方法3: 使用隨機森林進行特徵選擇\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "feature_importance_rf = rf.feature_importances_\n",
    "print(\"Feature Importance (Random Forest):\")\n",
    "print(feature_importance_rf)\n",
    "\n",
    "\n",
    "# 評估特徵的影響\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy (Decision Tree):\", accuracy)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy (Random Forest):\", accuracy_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
